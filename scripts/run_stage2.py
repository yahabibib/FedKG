from src.core.server import FederatedServer
from src.core.client import FederatedClient
from src.data.preprocessor import DataPreprocessor
from src.data.loader import DataLoader
from src.utils.metrics import Evaluator
from src.utils.logger import setup_logger, ResultRecorder
from src.utils.config import Config
import sys
import os
import torch
import torch.nn.functional as F
import argparse
from torch.utils.tensorboard import SummaryWriter
from tqdm import tqdm

# ==========================================
# ğŸš€ è·¯å¾„ä¿®å¤
# ==========================================
current_file_path = os.path.abspath(__file__)
current_dir = os.path.dirname(current_file_path)
project_root = os.path.dirname(current_dir)
if project_root not in sys.path:
    sys.path.insert(0, project_root)
# ==========================================


def parse_args():
    parser = argparse.ArgumentParser(
        description="Fed-LLM-SBERT Stage 2 Runner")
    parser.add_argument("--mode", type=str, default="full",
                        choices=["full", "no_llm", "no_mining"],
                        help="é€‰æ‹©å®éªŒæ¨¡å¼: full(å®Œæ•´), no_llm(æ— LLMå¢å¼º), no_mining(æ— è‡ªè®­ç»ƒ)")
    parser.add_argument("--rounds", type=int, default=None,
                        help="è¦†ç›– Config ä¸­çš„è”é‚¦è½®æ¬¡")
    return parser.parse_args()


def generate_pseudo_pairs(emb1, emb2, valid_ids_1, valid_ids_2, threshold=0.75, device='cpu'):
    """åŸºäºåŒå‘æœ€è¿‘é‚»æŒ–æ˜ä¼ªå¯¹é½"""
    emb1 = F.normalize(emb1.to(device), dim=1)
    emb2 = F.normalize(emb2.to(device), dim=1)
    sim_mat = torch.mm(emb1, emb2.T)

    values_1, indices_1 = torch.max(sim_mat, dim=1)
    values_2, indices_2 = torch.max(sim_mat, dim=0)

    pseudo_pairs = []
    valid_set_1 = set(valid_ids_1)
    valid_set_2 = set(valid_ids_2)

    for i in range(len(emb1)):
        if i not in valid_set_1:
            continue
        j = indices_1[i].item()
        if j not in valid_set_2:
            continue

        if indices_2[j].item() == i:
            if values_1[i].item() > threshold:
                pseudo_pairs.append((i, j))
    return pseudo_pairs


def main():
    args = parse_args()
    cfg = Config()

    # æ ¹æ® Argument åŠ¨æ€è°ƒæ•´é…ç½®
    exp_name = "FedAnchor (Full)"
    cache_suffix = "finetuned"
    total_iterations = 5

    # --- 1. æ¨¡å¼åˆ‡æ¢é€»è¾‘ ---
    if args.mode == "no_llm":
        exp_name = "No LLM (Raw SBERT)"
        # å¼ºåˆ¶ä½¿ç”¨åŸå§‹å¤šè¯­è¨€ BERTï¼Œä¸ä½¿ç”¨ Stage 1 çš„äº§å‡º
        cfg.sbert_model_path = "sentence-transformers/paraphrase-multilingual-mpnet-base-v2"
        cache_suffix = "raw"  # ä½¿ç”¨ä¸åŒçš„ç¼“å­˜æ–‡ä»¶åï¼Œé¿å…å†²çª

    elif args.mode == "no_mining":
        exp_name = "No Mining (Iter=1)"
        total_iterations = 1  # åªè·‘ç¬¬ä¸€è½®ï¼Œä¸è¿›è¡ŒæŒ–æ˜

    if args.rounds:
        cfg.fl_rounds = args.rounds

    # åˆå§‹åŒ– Logger
    logger = setup_logger(f"Stage2_{args.mode}")
    recorder = ResultRecorder()
    writer = SummaryWriter(log_dir=f"logs/tensorboard/{args.mode}")

    logger.info(f"ğŸ¬ Starting Experiment: [{exp_name}]")
    logger.info(f"   Mode: {args.mode}")
    logger.info(f"   SBERT: {cfg.sbert_model_path}")
    logger.info(f"   Iterations: {total_iterations}")

    # 2. æ•°æ®åŠ è½½
    loader = DataLoader(cfg)
    preprocessor = DataPreprocessor(cfg)

    id2uri_1, uri2id_1 = loader.load_id_map("ent_ids_1")
    trip1 = loader.load_triples("triples_1")
    id2uri_2, uri2id_2 = loader.load_id_map("ent_ids_2")
    trip2 = loader.load_triples("triples_2")

    num_ent_1 = max(id2uri_1.keys()) + 1 if id2uri_1 else 0
    num_ent_2 = max(id2uri_2.keys()) + 1 if id2uri_2 else 0

    attr1 = loader.load_pickle_descriptions("description1.pkl", uri2id_1)
    attr2 = loader.load_pickle_descriptions("description2.pkl", uri2id_2)
    test_pairs = loader.load_alignment_pairs("ref_pairs")

    # 3. é¢„å¤„ç†
    adj1 = preprocessor.build_adjacency_matrix(trip1, num_ent_1)
    adj2 = preprocessor.build_adjacency_matrix(trip2, num_ent_2)

    # è®¡ç®— SBERT (æ³¨æ„ cache_suffix çš„å˜åŒ–)
    emb1 = preprocessor.compute_sbert_embeddings(
        attr1, list(id2uri_1.keys()), id2uri_1, f"sbert_kg1_{cache_suffix}", model_path=cfg.sbert_model_path
    )
    emb2 = preprocessor.compute_sbert_embeddings(
        attr2, list(id2uri_2.keys()), id2uri_2, f"sbert_kg2_{cache_suffix}", model_path=cfg.sbert_model_path
    )

    # 4. åˆå§‹åŒ–è”é‚¦ç»„ä»¶
    server = FederatedServer(cfg)
    client1 = FederatedClient(
        "C1", cfg, {'adj': adj1, 'num_ent': num_ent_1, 'anchors': emb1})
    client2 = FederatedClient(
        "C2", cfg, {'adj': adj2, 'num_ent': num_ent_2, 'anchors': emb2})
    evaluator = Evaluator(cfg.device)

    global_weights = None
    best_hits1 = 0.0
    final_mrr = 0.0

    # 5. åŒå±‚å¾ªç¯è®­ç»ƒ
    for iteration in range(total_iterations):
        logger.info(
            f"\nğŸ”„ Self-Training Iteration {iteration + 1}/{total_iterations}")
        current_fl_rounds = cfg.fl_rounds if iteration == 0 else 30

        # å†…å±‚å¾ªç¯: FL Training
        pbar = tqdm(range(current_fl_rounds),
                    desc=f"Iter {iteration+1}", dynamic_ncols=True)
        for r in pbar:
            w1, loss1 = client1.train_local(global_weights)
            w2, loss2 = client2.train_local(global_weights)

            if cfg.use_aggregation:
                global_weights = server.aggregate([w1, w2])

            if (r + 1) % 10 == 0:
                pbar.set_postfix({'loss': f"{loss1:.3f}"})
                writer.add_scalars(
                    'Loss', {'C1': loss1, 'C2': loss2}, iteration * 100 + r)

        # Iteration ç»“æŸè¯„ä¼°
        logger.info("   Evaluating...")
        final_emb1_tensor = client1.get_embeddings()
        final_emb2_tensor = client2.get_embeddings()

        dict_emb1 = {eid: final_emb1_tensor[eid] for eid in id2uri_1.keys(
        ) if eid < len(final_emb1_tensor)}
        dict_emb2 = {eid: final_emb2_tensor[eid] for eid in id2uri_2.keys(
        ) if eid < len(final_emb2_tensor)}

        hits, mrr = evaluator.evaluate(
            test_pairs, dict_emb1, dict_emb2,
            sbert_src=emb1, sbert_tgt=emb2, alpha=cfg.eval_fusion_alpha
        )

        logger.info(
            f"   ğŸ“ˆ Iter {iteration+1} Result: Hits@1={hits[1]:.2f}% | MRR={mrr:.4f}")

        if hits[1] > best_hits1:
            best_hits1 = hits[1]
            final_mrr = mrr
            # åªæœ‰ Full æ¨¡å¼æ‰è¦†ç›–ä¿å­˜ best modelï¼Œé¿å…æ¶ˆèå®éªŒè¦†ç›–æ‰å¥½æ¨¡å‹
            if args.mode == "full":
                if not os.path.exists("output/checkpoints"):
                    os.makedirs("output/checkpoints")
                torch.save(client1.model.state_dict(),
                           "output/checkpoints/c1_best.pth")
                torch.save(client2.model.state_dict(),
                           "output/checkpoints/c2_best.pth")

        # -------------------------------------------------------
        # æ ¸å¿ƒé€»è¾‘å‡çº§ï¼šåŒæ¨¡èåˆæŒ–æ˜ (Fusion Mining)
        # -------------------------------------------------------
        if iteration < total_iterations - 1:
            # é˜ˆå€¼ç­–ç•¥
            current_threshold = 0.75 + (iteration * 0.05)
            logger.info(
                f"   â›ï¸  Mining pseudo-labels (Threshold={current_threshold:.2f})...")

            # ã€å‡çº§ç‚¹ã€‘ä¸å†åªç”¨ GCN ç‰¹å¾ï¼Œè€Œæ˜¯ç”¨ (GCN + SBERT) çš„èåˆç‰¹å¾æ¥æŒ–æ˜
            # è¿™æ ·æ—¢èƒ½åˆ©ç”¨ GCN çš„ç»“æ„å‘ç°èƒ½åŠ›ï¼Œåˆæœ‰ SBERT çš„è¯­ä¹‰å…œåº•ï¼Œé˜²æ­¢ GCN çè’™

            # 1. å½’ä¸€åŒ–å¹¶ç§»åŠ¨åˆ°åŒä¸€è®¾å¤‡
            gcn_emb1 = F.normalize(final_emb1_tensor.to(cfg.device))
            gcn_emb2 = F.normalize(final_emb2_tensor.to(cfg.device))

            # emb1, emb2 æ˜¯æœ€å¼€å§‹åŠ è½½çš„ SBERT åˆå§‹å‘é‡ (åœ¨ main å‡½æ•°å¼€å¤´å®šä¹‰çš„)
            # ç¡®ä¿å®ƒä»¬ä¹Ÿæ˜¯ Tensor å¹¶ä¸”åœ¨ device ä¸Š
            # æ³¨æ„ï¼šemb1 æ˜¯ dictï¼Œéœ€è¦è½¬æˆ tensor çŸ©é˜µ (æŒ‰ ID é¡ºåº)
            def dict_to_tensor(emb_dict, num_ent, dim, dev):
                mat = torch.zeros(num_ent, dim, device=dev)
                # åªå¡«å…¥å­˜åœ¨çš„ IDï¼Œå…¶ä»–é»˜è®¤ä¸º 0
                for k, v in emb_dict.items():
                    if k < num_ent:
                        mat[k] = v.to(dev)
                return mat

            sbert_mat1 = dict_to_tensor(
                emb1, num_ent_1, cfg.bert_dim, cfg.device)
            sbert_mat2 = dict_to_tensor(
                emb2, num_ent_2, cfg.bert_dim, cfg.device)
            sbert_mat1 = F.normalize(sbert_mat1)
            sbert_mat2 = F.normalize(sbert_mat2)

            # 2. èåˆ (ä½¿ç”¨é…ç½®é‡Œçš„ alpha)
            alpha = cfg.eval_fusion_alpha
            fused_1 = alpha * gcn_emb1 + (1 - alpha) * sbert_mat1
            fused_2 = alpha * gcn_emb2 + (1 - alpha) * sbert_mat2

            # 3. æŒ–æ˜
            new_pairs = generate_pseudo_pairs(
                fused_1, fused_2,
                list(id2uri_1.keys()), list(id2uri_2.keys()),
                threshold=current_threshold, device=cfg.device
            )

            logger.info(f"   Found {len(new_pairs)} pseudo-pairs.")

            # 4. æ›´æ–°
            if len(new_pairs) > 0:
                # æ³¨æ„ï¼šè™½ç„¶æ˜¯ç”¨èåˆç‰¹å¾æŒ–æ˜çš„ï¼Œä½†æ›´æ–°é”šç‚¹æ—¶ï¼Œ
                # ä¾ç„¶æ˜¯æŠŠã€å¯¹æ–¹å½“å‰çš„èåˆç‰¹å¾ã€‘æˆ–è€…ã€å¯¹æ–¹å½“å‰çš„ GCN ç‰¹å¾ã€‘ä½œä¸ºç›®æ ‡ï¼Ÿ
                # å»ºè®®ï¼šè®©æ¨¡å‹å»æ‹Ÿåˆå¯¹æ–¹çš„ GCN ç‰¹å¾ï¼ˆå› ä¸º SBERT éƒ¨åˆ†å®ƒå·²ç»å­¦è¿‡äº†ï¼‰ï¼Œæˆ–è€…æ‹Ÿåˆèåˆç‰¹å¾ã€‚
                # FedAnchor åŸæ–‡é€šå¸¸æŒ‡å¼•å»æ‹Ÿåˆå¯¹æ–¹çš„é«˜å±‚ç‰¹å¾ã€‚è¿™é‡Œæˆ‘ä»¬ç”¨ GCN ç‰¹å¾æ¯”è¾ƒçº¯ç²¹ã€‚
                update_c1 = {i: final_emb2_tensor[j].to(
                    cfg.device) for i, j in new_pairs}
                update_c2 = {j: final_emb1_tensor[i].to(
                    cfg.device) for i, j in new_pairs}
                client1.update_anchors(update_c1)
                client2.update_anchors(update_c2)
            else:
                logger.warning("   No pseudo-pairs found.")

    logger.info(f"ğŸ {exp_name} Finished. Best Hits@1: {best_hits1:.2f}%")
    writer.close()

    # è‡ªåŠ¨è®°å½•ç»“æœåˆ° JSON
    recorder.add_record(exp_name, {"hits1": best_hits1, "mrr": final_mrr}, {
                        "mode": args.mode})


if __name__ == "__main__":
    main()
