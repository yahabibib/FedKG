# scripts/run_stage1.py
from src.llm.finetuner import SBERTFinetuner
from src.llm.polisher import KnowledgePolisher
from src.data.loader import DataLoader
from src.utils.logger import setup_logger
from src.utils.config import Config
import sys
import os
import pickle
from collections import defaultdict

# å°†é¡¹ç›®æ ¹ç›®å½•åŠ å…¥è·¯å¾„ï¼Œç¡®ä¿èƒ½å¯¼å…¥ src
sys.path.append(os.getcwd())


def prepare_triples_text(ent_map, triples, rel_map, attr_map):
    """è¾…åŠ©å‡½æ•°ï¼šå°†ä¸‰å…ƒç»„æ•´ç†ä¸º Prompt æ‰€éœ€çš„åˆ—è¡¨"""
    adj = defaultdict(list)
    for h, r, t in triples:
        adj[h].append((r, t))

    tasks = []
    # éå†æ‰€æœ‰å®ä½“
    for eid, uri in ent_map.items():
        # å¦‚æœæ²¡æœ‰é‚»å±…ï¼Œè·³è¿‡
        if eid not in adj:
            continue

        neighbors = adj[eid][:5]  # é™åˆ¶é‚»å±…æ•°é‡
        relations_str = []

        # ç®€å•æ¸…æ´—åå­—çš„ lambda
        def clean(u): return u.split('/')[-1].replace('_', ' ')

        name = clean(uri)

        for r, t in neighbors:
            r_name = clean(rel_map.get(r, str(r)))
            t_name = clean(ent_map.get(t, str(t)))
            # è·å–å°¾å®ä½“èƒŒæ™¯ (å–å‰50å­—ç¬¦)
            t_desc = str(attr_map.get(t, ""))[:50]

            line = f"- å…³ç³»: {r_name} -> å¯¹è±¡: {t_name}"
            if t_desc:
                line += f" (èƒŒæ™¯: {t_desc})"
            relations_str.append(line)

        tasks.append({
            "eid": eid,
            "name": name,
            "relations": relations_str,
            "raw_desc": attr_map.get(eid, name)  # åŸå§‹æè¿°ä½œä¸º Anchor
        })
    return tasks


def main():
    cfg = Config()
    logger = setup_logger("Stage1_Polishing")
    logger.info("ğŸ¬ Starting Stage 1: LLM Polishing & SBERT Fine-tuning")

    loader = DataLoader(cfg)

    # 1. åŠ è½½æ•°æ®
    logger.info("Loading KG1 data...")
    ent1, _ = loader.load_id_map("ent_ids_1")
    rel1, _ = loader.load_id_map("rel_ids_1")
    trip1 = loader.load_triples("triples_1")
    attr1 = loader.load_pickle_descriptions("description1.pkl", ent1)

    # 2. å‡†å¤‡ LLM ä»»åŠ¡
    tasks = prepare_triples_text(ent1, trip1, rel1, attr1)
    logger.info(f"Prepared {len(tasks)} entities for polishing.")

    # 3. æ‰§è¡Œ LLM æ¶¦è‰²
    # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ¶¦è‰²ç»“æœï¼Œé¿å…é‡å¤è·‘ (å¾ˆæ…¢)
    polished_file = os.path.join(
        cfg.project_root, cfg.relative_data_path, "polished_data_kg1.pkl")

    if os.path.exists(polished_file):
        logger.info(
            f"Found existing polished data: {polished_file}, skipping LLM inference.")
        with open(polished_file, 'rb') as f:
            polished_results = pickle.load(f)
    else:
        logger.info("Initializing LLM for inference...")
        polisher = KnowledgePolisher(cfg)

        prompts = []
        for t in tasks:
            p = polisher.construct_prompt(t['name'], t['relations'], lang='zh')
            prompts.append(p)

        # æ‰¹é‡ç”Ÿæˆ
        # âš ï¸ æ³¨æ„ï¼šå¦‚æœæ˜¯ CPU è·‘ï¼Œå»ºè®®æŠŠ tasks[:10] å…ˆåˆ‡ç‰‡æµ‹è¯•ä¸€ä¸‹
        generated_texts = polisher.batch_generate(prompts, batch_size=4)

        polished_results = {}
        for task, text in zip(tasks, generated_texts):
            polished_results[task['eid']] = text

        # ä¿å­˜
        with open(polished_file, 'wb') as f:
            pickle.dump(polished_results, f)

        polisher.clean_memory()

    # 4. æ‰§è¡Œ SBERT å¾®è°ƒ
    logger.info("Preparing Fine-tuning pairs...")
    train_pairs = []

    for t in tasks:
        eid = t['eid']
        if eid in polished_results:
            anchor = t['raw_desc']
            positive = polished_results[eid]
            # åªæœ‰å½“ä¸¤ä¸ªæ–‡æœ¬éƒ½è¶³å¤Ÿé•¿æ—¶æ‰è®­ç»ƒ
            if len(anchor) > 5 and len(positive) > 5:
                train_pairs.append((anchor, positive))

    finetuner = SBERTFinetuner(cfg)
    finetuner.fine_tune(
        train_pairs,
        # ä¿å­˜åˆ° output/fine_tuned_models/exp4...
        output_path=cfg.sbert_model_path,
        epochs=3
    )

    logger.info("ğŸ‰ Stage 1 Completed!")


if __name__ == "__main__":
    main()
