# src/core/server.py
import torch
from sentence_transformers import SentenceTransformer
from collections import OrderedDict
import os
import logging

log = logging.getLogger(__name__)


class Server:
    def __init__(self, cfg):
        self.cfg = cfg
        # Server æ°¸è¿œé©»ç•™ CPU
        log.info("[Server] Initializing on CPU...")
        self.global_model = SentenceTransformer(
            cfg.task.model.name, device='cpu')

    def aggregate(self, client_weights_list):
        """
        FedAvg èšåˆç­–ç•¥
        :param client_weights_list: List[OrderedDict] - å®¢æˆ·ç«¯ state_dict åˆ—è¡¨
        """
        if not client_weights_list:
            return None

        # log.info(f"[Server] Aggregating parameters from {len(client_weights_list)} clients...")
        avg_weights = OrderedDict()

        # è·å–ç¬¬ä¸€ä¸ªå®¢æˆ·ç«¯çš„ keys ä½œä¸ºåŸºå‡†
        keys = client_weights_list[0].keys()

        for key in keys:
            # ç¡®ä¿æ‰€æœ‰ tensor éƒ½åœ¨ CPU ä¸Šè¿›è¡Œå¹³å‡
            tensors = [w[key].to('cpu') for w in client_weights_list]
            # Stack åæ±‚å¹³å‡
            avg_weights[key] = torch.stack(tensors).mean(dim=0)

        # æ›´æ–°å…¨å±€æ¨¡å‹
        self.global_model.load_state_dict(avg_weights)
        return avg_weights

    def get_global_weights(self):
        return self.global_model.state_dict()

    def save_model(self, suffix="best"):
        """ä¿å­˜ SBERT å…¨å±€æ¨¡å‹ (å« Config å’Œ Tokenizer)"""
        save_dir = os.path.join(
            self.cfg.task.checkpoint.save_dir,
            f"sbert_{self.cfg.task.strategy.text_mode}_{suffix}"
        )

        if not os.path.exists(save_dir):
            os.makedirs(save_dir)

        log.info(f"ğŸ’¾ Saving global model to: {save_dir}")
        self.global_model.save(save_dir)
        log.info("âœ… Model saved successfully!")
