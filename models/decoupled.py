# ğŸ“„ AiStudy/models/decoupled.py
import torch
import torch.nn as nn
import torch.nn.functional as F
from .gcn import GCNLayer  # å¤ç”¨ä¹‹å‰çš„ GCNLayer


class DecoupledModel(nn.Module):
    """
    ã€è§£è€¦æ¨¡å‹æ¶æ„ã€‘
    - struct_encoder (GCN): ç§æœ‰å±‚ï¼Œè´Ÿè´£æå–æœ¬åœ°ç»“æ„ç‰¹å¾ (ä¸èšåˆ)
    - semantic_projector (MLP): å…¬å…±å±‚ï¼Œè´Ÿè´£æ˜ å°„åˆ°è¯­ä¹‰ç©ºé—´ (èšåˆ)
    """

    def __init__(self, num_entities, feature_dim, hidden_dim, output_dim, dropout=0.3):
        super().__init__()

        print(f"    [Model Init] Decoupled: GCN(Private) -> MLP(Shared)")

        # --- 1. ç§æœ‰ç»“æ„ç¼–ç å™¨ (Private) ---
        # å¯å­¦ä¹ çš„åˆå§‹èŠ‚ç‚¹ç‰¹å¾
        self.initial_features = nn.Parameter(
            torch.randn(num_entities, feature_dim))
        nn.init.xavier_uniform_(self.initial_features)

        # GCN å±‚ (åªè´Ÿè´£æå–ç»“æ„ï¼Œä¸è´Ÿè´£å¯¹é½)
        self.struct_encoder = nn.ModuleList([
            GCNLayer(feature_dim, hidden_dim),
            # å¯ä»¥åŠ æ›´å¤šå±‚ï¼Œè¿™é‡Œä¿æŒåŒå±‚ç»“æ„
        ])

        # --- 2. å…¬å…±è¯­ä¹‰æ˜ å°„å™¨ (Shared) ---
        # è¿™æ˜¯ä¸€ä¸ª MLPï¼Œè´Ÿè´£æŠŠç»“æ„ç‰¹å¾ç¿»è¯‘æˆ SBERT è¯­ä¹‰
        # å®ƒçš„è¾“å…¥æ˜¯ GCN çš„è¾“å‡º (hidden_dim)ï¼Œè¾“å‡ºæ˜¯ SBERT ç»´åº¦ (output_dim)
        self.semantic_projector = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim),
            nn.BatchNorm1d(hidden_dim),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim, output_dim)
        )

        self.dropout = dropout

    def forward(self, adj):
        x = self.initial_features

        # 1. ç»è¿‡ç§æœ‰ GCN ç¼–ç 
        for layer in self.struct_encoder:
            x = layer(x, adj)
            x = F.relu(x)
            x = F.dropout(x, self.dropout, training=self.training)

        # 2. ç»è¿‡å…¬å…± MLP æ˜ å°„
        # æ³¨æ„ï¼šGCN çš„è¾“å‡ºç»è¿‡ MLP è°ƒæ•´åï¼Œæ‰å»å’Œ SBERT åš Loss
        x = self.semantic_projector(x)

        return x
