# ğŸ“„ evaluate_fusion.py
# ã€æœ€ç»ˆé€‚é…ç‰ˆã€‘æ”¯æŒ Relation-Aware GCN çš„èåˆè¯„ä¼°è„šæœ¬
# å®ƒå¯ä»¥åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹ (Checkpoint)ï¼Œå¹¶æµ‹è¯•ä¸åŒ Alpha ä¸‹çš„èåˆæ•ˆæœ

import torch
import torch.nn.functional as F
import os
import config
import data_loader
import precompute
import fl_core
from tqdm import tqdm

# ==========================================
# ğŸ”§ èåˆè¯„ä¼°çš„æ ¸å¿ƒå‡½æ•°
# ==========================================


@torch.no_grad()
def run_fusion_eval(test_pairs, gcn_emb_1, gcn_emb_2, sbert_emb_1, sbert_emb_2, alpha=0.6, k_values=[1, 10, 50]):
    """
    alpha: èåˆæƒé‡ã€‚
           alpha=1.0 -> çº¯ GCN
           alpha=0.0 -> çº¯ SBERT
           alpha=0.5 -> èåˆ
    """
    print(f"\nâš¡ï¸ å¼€å§‹èåˆè¯„ä¼° (Alpha = {alpha})")
    print(f"   è¯´æ˜: {int(alpha*100)}% ç»“æ„(GCN) + {int((1-alpha)*100)}% è¯­ä¹‰(SBERT)")

    device = config.DEVICE

    # 1. å‡†å¤‡æœ‰æ•ˆå¯¹
    valid_pairs = []
    kg1_ids, kg2_ids = set(), set()

    for i1, i2 in test_pairs:
        if i1 in gcn_emb_1 and i2 in gcn_emb_2:
            valid_pairs.append((i1, i2))
            kg1_ids.add(i1)
            kg2_ids.add(i2)

    kg1_ids = sorted(list(kg1_ids))
    kg2_ids = sorted(list(kg2_ids))

    id2idx_1 = {id: i for i, id in enumerate(kg1_ids)}
    id2idx_2 = {id: i for i, id in enumerate(kg2_ids)}

    # 2. å †å å¹¶å½’ä¸€åŒ– - GCN éƒ¨åˆ†
    t_gcn_1 = torch.stack([gcn_emb_1[i] for i in kg1_ids]).to(device)
    t_gcn_2 = torch.stack([gcn_emb_2[i] for i in kg2_ids]).to(device)
    t_gcn_1 = F.normalize(t_gcn_1, p=2, dim=1)
    t_gcn_2 = F.normalize(t_gcn_2, p=2, dim=1)

    sim_gcn = torch.mm(t_gcn_1, t_gcn_2.T)

    # 3. å †å å¹¶å½’ä¸€åŒ– - SBERT éƒ¨åˆ†
    t_sb_1 = torch.stack([sbert_emb_1[i] for i in kg1_ids]).to(device)
    t_sb_2 = torch.stack([sbert_emb_2[i] for i in kg2_ids]).to(device)
    t_sb_1 = F.normalize(t_sb_1, p=2, dim=1)
    t_sb_2 = F.normalize(t_sb_2, p=2, dim=1)

    sim_sb = torch.mm(t_sb_1, t_sb_2.T)

    # 4. åŠ æƒèåˆ
    sim_final = (alpha * sim_gcn) + ((1.0 - alpha) * sim_sb)
    sim_final = sim_final.cpu()

    # 5. è®¡ç®—æŒ‡æ ‡
    hits_at = {k: 0 for k in k_values}
    mrr = 0.0

    for i1, i2 in tqdm(valid_pairs, desc="   Ranking", leave=False):
        idx1 = id2idx_1[i1]
        target_idx2 = id2idx_2[i2]

        scores = sim_final[idx1]
        rank = (torch.argsort(scores, descending=True)
                == target_idx2).nonzero().item() + 1

        mrr += 1.0 / rank
        for k in k_values:
            if rank <= k:
                hits_at[k] += 1

    count = len(valid_pairs)
    mrr /= count
    hits_at = {k: (v/count)*100 for k, v in hits_at.items()}

    print(
        f"   ğŸ† ç»“æœ: Hits@1={hits_at[1]:.2f} | Hits@10={hits_at[10]:.2f} | MRR={mrr:.4f}")
    return hits_at, mrr

# ==========================================
# ğŸš€ ä¸»æµç¨‹
# ==========================================


def main():
    print(f"ğŸ”¥ å¯åŠ¨åŒæ¨¡èåˆè„šæœ¬ (Relation-Aware Version)")
    print(f"ğŸ’» è®¾å¤‡: {config.DEVICE}")

    # --- 1. åŠ è½½æ•°æ® ---
    print("\n[1/4] åŠ è½½åŸºç¡€æ•°æ®...")
    ent_1 = data_loader.load_id_map(config.BASE_PATH + "ent_ids_1")
    rel_1 = data_loader.load_id_map(config.BASE_PATH + "rel_ids_1")  # éœ€è¦å…³ç³»ID
    trip_1 = data_loader.load_triples(config.BASE_PATH + "triples_1")
    num_ent_1 = max(list(ent_1[0].keys())) + 1

    ent_2 = data_loader.load_id_map(config.BASE_PATH + "ent_ids_2")
    rel_2 = data_loader.load_id_map(config.BASE_PATH + "rel_ids_2")  # éœ€è¦å…³ç³»ID
    trip_2 = data_loader.load_triples(config.BASE_PATH + "triples_2")
    num_ent_2 = max(list(ent_2[0].keys())) + 1

    test_pairs = data_loader.load_alignment_pairs(
        config.BASE_PATH + "ref_pairs")

    # --- 2. å‡†å¤‡ SBERT (è¯­ä¹‰é”šç‚¹) ---
    print("\n[2/4] åŠ è½½ SBERT ç¼“å­˜...")
    cache_1 = "cache/sbert_KG1.pt"
    cache_2 = "cache/sbert_KG2.pt"

    if os.path.exists(cache_1) and os.path.exists(cache_2):
        sb_1 = torch.load(cache_1, map_location=config.DEVICE)
        sb_2 = torch.load(cache_2, map_location=config.DEVICE)
        print("   âœ… SBERT ç¼“å­˜åŠ è½½æˆåŠŸï¼")
    else:
        print("   âŒ æœªæ‰¾åˆ° SBERT ç¼“å­˜ï¼Œè¯·å…ˆè¿è¡Œ main.py ç”Ÿæˆç¼“å­˜ã€‚")
        return

    # --- 3. å‡†å¤‡ GCN æ¨¡å‹ (ç»“æ„ç‰¹å¾) ---
    print("\n[3/4] åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹...")

    # âš ï¸ è¯·ä¿®æ”¹è¿™é‡Œä¸ºä½ æƒ³è¦æµ‹è¯•çš„ Iteration (é€šå¸¸æ˜¯ 5)
    TARGET_ITER = 5
    ckpt_c1 = f"checkpoints/c1_iter_{TARGET_ITER}.pth"
    ckpt_c2 = f"checkpoints/c2_iter_{TARGET_ITER}.pth"

    if not (os.path.exists(ckpt_c1) and os.path.exists(ckpt_c2)):
        print(f"   âŒ æ‰¾ä¸åˆ° Checkpoint æ–‡ä»¶: {ckpt_c1}")
        print("   è¯·ä¿®æ”¹è„šæœ¬ä¸­çš„ TARGET_ITERã€‚")
        return

    # ğŸ”¥ [ä¿®æ”¹] æ„å»ºå¸¦å…³ç³»çš„å›¾ç»“æ„ (Edge Index & Type)
    print("   æ„å»ºå¸¦å…³ç³»çš„å›¾ç»“æ„...")
    edge_index_1, edge_type_1 = precompute.build_graph_data(
        trip_1, num_ent_1, len(rel_1[0]))
    edge_index_2, edge_type_2 = precompute.build_graph_data(
        trip_2, num_ent_2, len(rel_2[0]))

    # åˆå§‹åŒ–ç©ºæ¨¡å‹
    print("   åˆå§‹åŒ–æ¨¡å‹ç»“æ„ (Relation-Aware)...")
    config.MODEL_ARCH = 'decoupled'

    # åˆå§‹åŒ– Client (ä¼ å…¥ edge_index, edge_type, num_rel)
    # æ³¨æ„ï¼šä¸éœ€è¦ä¼  rel_sbertï¼Œå› ä¸ºæˆ‘ä»¬ä¼šåŠ è½½ checkpoint è¦†ç›–æƒé‡
    c1 = fl_core.Client("C1_Eval", config.DEVICE,
                        bert={0: torch.zeros(768)}, num_ent=num_ent_1,
                        num_rel=len(rel_1[0]),  # å¿…é¡»ä¼ 
                        edge_index=edge_index_1, edge_type=edge_type_1)

    c1.model.load_state_dict(torch.load(ckpt_c1, map_location=config.DEVICE))
    c1.model.eval()

    c2 = fl_core.Client("C2_Eval", config.DEVICE,
                        bert={0: torch.zeros(768)}, num_ent=num_ent_2,
                        num_rel=len(rel_2[0]),  # å¿…é¡»ä¼ 
                        edge_index=edge_index_2, edge_type=edge_type_2)

    c2.model.load_state_dict(torch.load(ckpt_c2, map_location=config.DEVICE))
    c2.model.eval()

    print("   âœ… æ¨¡å‹åŠ è½½å®Œæ¯•ï¼å¼€å§‹æ¨ç† GCN ç‰¹å¾...")
    with torch.no_grad():
        # ğŸ”¥ [ä¿®æ”¹] æ¨ç†æ—¶ä¼ å…¥ Edge Index å’Œ Type
        out_1 = c1.model(c1.edge_index, c1.edge_type).detach().cpu()
        out_2 = c2.model(c2.edge_index, c2.edge_type).detach().cpu()

        gcn_emb_1 = {i: out_1[i] for i in range(len(out_1))}
        gcn_emb_2 = {i: out_2[i] for i in range(len(out_2))}

    # --- 4. æ‰§è¡Œèåˆè¯„ä¼° ---
    print("\n[4/4] æœ€ç»ˆå¯¹å†³ï¼šä¸åŒ Alpha çš„æ•ˆæœå¯¹æ¯”")
    print("=" * 60)

    # å»ºè®®æ‰«æèŒƒå›´æ›´å¹¿ä¸€ç‚¹ï¼Œå› ä¸ºæ¨¡å‹å˜å¼ºäº†
    alphas_to_test = [0.0, 1.0, 0.4, 0.5, 0.6, 0.7, 0.8]

    best_h1 = 0
    best_alpha = 0

    for a in alphas_to_test:
        h1, _ = run_fusion_eval(test_pairs, gcn_emb_1,
                                gcn_emb_2, sb_1, sb_2, alpha=a)
        if h1[1] > best_h1:
            best_h1 = h1[1]
            best_alpha = a

    print("\n" + "="*60)
    print(f"ğŸ‰ æœ€ä½³é…ç½®: Alpha = {best_alpha}")
    print(f"ğŸ“ˆ æœ€ä½³ Hits@1: {best_h1:.2f}%")
    print("="*60)


if __name__ == "__main__":
    main()
