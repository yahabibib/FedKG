# ğŸ“„ eval_fusion.py
# ä¸“é—¨ç”¨äºâ€œåŒæ¨¡èåˆâ€æ¨ç†çš„ç‹¬ç«‹è„šæœ¬
# å®ƒå¯ä»¥åŠ è½½è®­ç»ƒå¥½çš„ GCN æ¨¡å‹ï¼Œå¹¶ä¸ SBERT è¿›è¡ŒåŠ æƒèåˆï¼Œç¬é—´æå‡æ•ˆæœï¼

import torch
import torch.nn.functional as F
import os
import config
import data_loader
import precompute
import fl_core
from tqdm import tqdm

# ==========================================
# ğŸ”§ èåˆè¯„ä¼°çš„æ ¸å¿ƒå‡½æ•° (æœ¬åœ°å®šä¹‰ï¼Œæ— éœ€ä¿®æ”¹ evaluate.py)
# ==========================================


@torch.no_grad()
def run_fusion_eval(test_pairs, gcn_emb_1, gcn_emb_2, sbert_emb_1, sbert_emb_2, alpha=0.6, k_values=[1, 10, 50]):
    """
    alpha: èåˆæƒé‡ã€‚
           alpha=1.0 -> çº¯ GCN
           alpha=0.0 -> çº¯ SBERT
           alpha=0.6 -> æ¨èèåˆæ¯”ä¾‹ (60% GCN + 40% SBERT)
    """
    print(f"\nâš¡ï¸ å¼€å§‹èåˆè¯„ä¼° (Alpha = {alpha})")
    print(f"   è¯´æ˜: {int(alpha*100)}% ç»“æ„(GCN) + {int((1-alpha)*100)}% è¯­ä¹‰(SBERT)")

    device = config.DEVICE

    # 1. å‡†å¤‡ ID åˆ—è¡¨
    # å‡è®¾è¾“å…¥çš„ embedding éƒ½æ˜¯å­—å…¸ {id: tensor}
    valid_pairs = []
    kg1_ids, kg2_ids = set(), set()

    for i1, i2 in test_pairs:
        if i1 in gcn_emb_1 and i2 in gcn_emb_2:
            valid_pairs.append((i1, i2))
            kg1_ids.add(i1)
            kg2_ids.add(i2)

    kg1_ids = sorted(list(kg1_ids))
    kg2_ids = sorted(list(kg2_ids))

    id2idx_1 = {id: i for i, id in enumerate(kg1_ids)}
    id2idx_2 = {id: i for i, id in enumerate(kg2_ids)}

    # 2. å †å å¹¶å½’ä¸€åŒ– - GCN éƒ¨åˆ†
    t_gcn_1 = torch.stack([gcn_emb_1[i] for i in kg1_ids]).to(device)
    t_gcn_2 = torch.stack([gcn_emb_2[i] for i in kg2_ids]).to(device)
    t_gcn_1 = F.normalize(t_gcn_1, p=2, dim=1)
    t_gcn_2 = F.normalize(t_gcn_2, p=2, dim=1)

    sim_gcn = torch.mm(t_gcn_1, t_gcn_2.T)

    # 3. å †å å¹¶å½’ä¸€åŒ– - SBERT éƒ¨åˆ†
    t_sb_1 = torch.stack([sbert_emb_1[i] for i in kg1_ids]).to(device)
    t_sb_2 = torch.stack([sbert_emb_2[i] for i in kg2_ids]).to(device)
    t_sb_1 = F.normalize(t_sb_1, p=2, dim=1)
    t_sb_2 = F.normalize(t_sb_2, p=2, dim=1)

    sim_sb = torch.mm(t_sb_1, t_sb_2.T)

    # 4. åŠ æƒèåˆ (å¹¿æ’­æœºåˆ¶è‡ªåŠ¨å¤„ç†)
    # final_sim = alpha * GCN + (1-alpha) * SBERT
    sim_final = (alpha * sim_gcn) + ((1.0 - alpha) * sim_sb)

    # ç§»å› CPU è®¡ç®—æ’å
    sim_final = sim_final.cpu()

    # 5. è®¡ç®—æŒ‡æ ‡
    hits_at = {k: 0 for k in k_values}
    mrr = 0.0

    for i1, i2 in tqdm(valid_pairs, desc="   Ranking", leave=False):
        idx1 = id2idx_1[i1]
        target_idx2 = id2idx_2[i2]

        scores = sim_final[idx1]
        # è·å–æ’åçš„ä½ç½® (ä»0å¼€å§‹æ‰€ä»¥+1)
        rank = (torch.argsort(scores, descending=True)
                == target_idx2).nonzero().item() + 1

        mrr += 1.0 / rank
        for k in k_values:
            if rank <= k:
                hits_at[k] += 1

    count = len(valid_pairs)
    mrr /= count
    hits_at = {k: (v/count)*100 for k, v in hits_at.items()}

    print(
        f"   ğŸ† ç»“æœ: Hits@1={hits_at[1]:.2f} | Hits@10={hits_at[10]:.2f} | MRR={mrr:.4f}")
    return hits_at, mrr

# ==========================================
# ğŸš€ ä¸»æµç¨‹
# ==========================================


# ... (å‰é¢çš„ import å’Œ run_fusion_eval å‡½æ•°ä¿æŒä¸å˜) ...

# ==========================================
# ğŸš€ ä¸»æµç¨‹ (ä¿®å¤ç‰ˆ)
# ==========================================
def main():
    print(f"ğŸ”¥ å¯åŠ¨åŒæ¨¡èåˆè„šæœ¬ (Ensemble Inference)")
    print(f"ğŸ’» è®¾å¤‡: {config.DEVICE}")

    # --- 1. åŠ è½½æ•°æ® ---
    print("\n[1/4] åŠ è½½åŸºç¡€æ•°æ®...")
    ent_1 = data_loader.load_id_map(config.BASE_PATH + "ent_ids_1")
    trip_1 = data_loader.load_triples(config.BASE_PATH + "triples_1")
    num_ent_1 = max(list(ent_1[0].keys())) + 1

    ent_2 = data_loader.load_id_map(config.BASE_PATH + "ent_ids_2")
    trip_2 = data_loader.load_triples(config.BASE_PATH + "triples_2")
    num_ent_2 = max(list(ent_2[0].keys())) + 1

    test_pairs = data_loader.load_alignment_pairs(
        config.BASE_PATH + "ref_pairs")

    # --- 2. å‡†å¤‡ SBERT (è¯­ä¹‰é”šç‚¹) ---
    print("\n[2/4] åŠ è½½ SBERT ç¼“å­˜...")
    cache_1 = "cache/sbert_KG1.pt"
    cache_2 = "cache/sbert_KG2.pt"

    if os.path.exists(cache_1) and os.path.exists(cache_2):
        sb_1 = torch.load(cache_1, map_location=config.DEVICE)
        sb_2 = torch.load(cache_2, map_location=config.DEVICE)
        print("   âœ… SBERT ç¼“å­˜åŠ è½½æˆåŠŸï¼")
    else:
        print("   âŒ æœªæ‰¾åˆ° SBERT ç¼“å­˜ï¼Œè¯·å…ˆè¿è¡Œ main.py ç”Ÿæˆç¼“å­˜ã€‚")
        return

    # --- 3. å‡†å¤‡ GCN æ¨¡å‹ (ç»“æ„ç‰¹å¾) ---
    print("\n[3/4] åŠ è½½è®­ç»ƒå¥½çš„ GCN æ¨¡å‹...")
    # âš ï¸ è¯·ç¡®ä¿è¿™é‡Œçš„ TARGET_ITER æ˜¯ä½ å®é™…è·‘å®Œçš„è½®æ•°
    TARGET_ITER = 5
    ckpt_c1 = f"checkpoints/c1_iter_{TARGET_ITER}.pth"
    ckpt_c2 = f"checkpoints/c2_iter_{TARGET_ITER}.pth"

    if not (os.path.exists(ckpt_c1) and os.path.exists(ckpt_c2)):
        print(f"   âŒ æ‰¾ä¸åˆ° Checkpoint æ–‡ä»¶: {ckpt_c1}")
        print("   è¯·ä¿®æ”¹è„šæœ¬ä¸­çš„ TARGET_ITER ä¸ºä½ å®é™…æ‹¥æœ‰çš„è½®æ¬¡ã€‚")
        return

    # æ„å»ºé‚»æ¥çŸ©é˜µ
    print("   æ„å»ºé‚»æ¥çŸ©é˜µ (å¦‚æœæ¯”è¾ƒå¤§è¯·ç¨ç­‰)...")

    # ã€å…³é”®ä¿®å¤ã€‘:
    # MPS (Mac) ä¸æ”¯æŒç¨€ç–å¼ é‡ï¼Œæ‰€ä»¥ adj å¿…é¡»ç•™åœ¨ CPUã€‚
    # CUDA (Nvidia) æ”¯æŒï¼Œæ‰€ä»¥å¦‚æœæ˜¯ cuda å¯ä»¥è½¬è¿‡å»ã€‚
    adj_1 = precompute.build_adjacency_matrix(trip_1, num_ent_1)
    adj_2 = precompute.build_adjacency_matrix(trip_2, num_ent_2)

    if config.DEVICE.type == 'cuda':
        adj_1 = adj_1.to(config.DEVICE)
        adj_2 = adj_2.to(config.DEVICE)
    else:
        print("   [æç¤º] æ£€æµ‹åˆ°é CUDA ç¯å¢ƒ (å¦‚ MPS/CPU)ï¼Œé‚»æ¥çŸ©é˜µå°†ä¿ç•™åœ¨å†…å­˜ä¸­ä»¥é¿å…å…¼å®¹æ€§é”™è¯¯ã€‚")

    # åˆå§‹åŒ–ç©ºæ¨¡å‹
    print("   åˆå§‹åŒ–æ¨¡å‹ç»“æ„...")
    config.MODEL_ARCH = 'decoupled'

    # æ³¨æ„ï¼šè¿™é‡Œåˆå§‹åŒ– Client æ—¶ï¼Œadj ä¼ è¿›å»æ˜¯ä»€ä¹ˆè®¾å¤‡å°±æ˜¯ä»€ä¹ˆè®¾å¤‡
    c1 = fl_core.Client("C1_Eval", config.DEVICE, bert={
                        0: torch.zeros(768)}, num_ent=num_ent_1, adj=adj_1)
    c1.model.load_state_dict(torch.load(ckpt_c1, map_location=config.DEVICE))
    c1.model.eval()

    c2 = fl_core.Client("C2_Eval", config.DEVICE, bert={
                        0: torch.zeros(768)}, num_ent=num_ent_2, adj=adj_2)
    c2.model.load_state_dict(torch.load(ckpt_c2, map_location=config.DEVICE))
    c2.model.eval()

    print("   âœ… æ¨¡å‹åŠ è½½å®Œæ¯•ï¼å¼€å§‹æ¨ç† GCN ç‰¹å¾...")
    with torch.no_grad():
        # è·å– GCN è¾“å‡º
        # æ¨¡å‹å†…éƒ¨çš„ GCNLayer ä¼šè‡ªåŠ¨å¤„ç† "MPSè¾“å…¥ + CPUçŸ©é˜µ" çš„æƒ…å†µ
        out_1 = c1.model(adj_1).detach().cpu()
        out_2 = c2.model(adj_2).detach().cpu()

        gcn_emb_1 = {i: out_1[i] for i in range(len(out_1))}
        gcn_emb_2 = {i: out_2[i] for i in range(len(out_2))}

    # --- 4. æ‰§è¡Œèåˆè¯„ä¼° ---
    print("\n[4/4] æœ€ç»ˆå¯¹å†³ï¼šä¸åŒ Alpha çš„æ•ˆæœå¯¹æ¯”")
    print("=" * 60)

    # ğŸ¯ æ­¥é•¿ 0.01 çš„åœ°æ¯¯å¼æœç´¢
    alphas_to_test = [
        0.40, 0.41, 0.42, 0.43, 0.44,
        0.45,
        0.46, 0.47, 0.48, 0.49, 0.50
    ]

    best_h1 = 0
    best_alpha = 0

    for a in alphas_to_test:
        h1, _ = run_fusion_eval(test_pairs, gcn_emb_1,
                                gcn_emb_2, sb_1, sb_2, alpha=a)
        if h1[1] > best_h1:
            best_h1 = h1[1]
            best_alpha = a

    print("\n" + "="*60)
    print(f"ğŸ‰ æœ€ä½³é…ç½®: Alpha = {best_alpha}")
    print(f"ğŸ“ˆ æœ€ä½³ Hits@1: {best_h1:.2f}%")
    print("="*60)


if __name__ == "__main__":
    main()
