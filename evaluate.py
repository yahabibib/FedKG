# ğŸ“„ evaluate.py
import torch
import torch.nn.functional as F
from tqdm import tqdm
import config


@torch.no_grad()
def evaluate_alignment(test_pairs, emb_dict_1, emb_dict_2, model_1, model_2, k_values,
                       sbert_1=None, sbert_2=None, alpha=None):
    """
    ã€å‡çº§ç‰ˆã€‘æ”¯æŒåŒæ¨¡èåˆè¯„ä¼°ã€‚
    å‚æ•°:
    - emb_dict_1/2: æ¨¡å‹è¾“å‡ºçš„ç»“æ„/æ˜ å°„ Embedding (å­—å…¸æ ¼å¼ {id: tensor})
    - sbert_1/2:    SBERT åŸå§‹è¯­ä¹‰ Embedding (å­—å…¸æ ¼å¼ {id: tensor})
    - alpha:        èåˆæƒé‡ã€‚None åˆ™ä½¿ç”¨ config ä¸­çš„é»˜è®¤å€¼ã€‚
    """

    # å¦‚æœæ²¡æœ‰ä¼  alphaï¼Œå°è¯•ä» config è¯»å–ï¼Œå¦‚æœ config ä¹Ÿæ²¡æœ‰ï¼Œé»˜è®¤ä¸º 1.0 (çº¯ç»“æ„)
    if alpha is None:
        alpha = getattr(config, 'EVAL_FUSION_ALPHA', 1.0)

    print(f"\n--- é˜¶æ®µå››ï¼šå¼€å§‹è¯„ä¼° (Alpha={alpha}) ---")
    if sbert_1 is not None and sbert_2 is not None and alpha < 1.0:
        print(
            f"   [Mode] Dual-Encoder Fusion ({int(alpha*100)}% GCN + {int((1-alpha)*100)}% SBERT)")
    else:
        print("   [Mode] Single Structure Model (GCN Only)")

    model_1.eval()
    model_2.eval()
    model_1.to(config.DEVICE)
    model_2.to(config.DEVICE)

    # 1. å‡†å¤‡æœ‰æ•ˆæµ‹è¯•å¯¹
    valid_test_pairs = []
    kg1_ids = set()
    kg2_ids = set()

    for id1, id2 in test_pairs:
        # ç¡®ä¿ ID åœ¨ä¸¤ä¸ªæ¨¡å‹çš„ Embedding ä¸­éƒ½å­˜åœ¨
        if id1 in emb_dict_1 and id2 in emb_dict_2:
            valid_test_pairs.append((id1, id2))
            kg1_ids.add(id1)
            kg2_ids.add(id2)

    kg1_ids = sorted(list(kg1_ids))
    kg2_ids = sorted(list(kg2_ids))

    # å»ºç«‹ ID åˆ° çŸ©é˜µç´¢å¼• çš„æ˜ å°„
    id_to_idx_1 = {id: i for i, id in enumerate(kg1_ids)}
    id_to_idx_2 = {id: i for i, id in enumerate(kg2_ids)}

    # 2. å‡†å¤‡ GCN/TransE ç»“æ„å‘é‡
    # æ³¨æ„ï¼šä¼ å…¥çš„ emb_dict_1 å·²ç»æ˜¯ tensor äº†ï¼Œè¿™é‡Œå †å èµ·æ¥
    emb_1_struct = torch.stack([emb_dict_1[i]
                               for i in kg1_ids]).to(config.DEVICE)
    emb_2_struct = torch.stack([emb_dict_2[i]
                               for i in kg2_ids]).to(config.DEVICE)

    # å¦‚æœè¿˜æœ‰æ¨¡å‹å±‚æ²¡è·‘ï¼ˆé’ˆå¯¹ ProjectionModelï¼‰ï¼Œè¿™é‡Œè·‘ä¸€ä¸‹
    # å¯¹äº GCN æ¥è¯´ï¼Œé€šå¸¸åœ¨å¤–éƒ¨å·²ç» inference å¥½äº†ï¼Œè¿™é‡Œ model_1 å¯èƒ½æ˜¯ Identity
    emb_1_struct = model_1(emb_1_struct)
    emb_2_struct = model_2(emb_2_struct)

    # å½’ä¸€åŒ–
    emb_1_struct = F.normalize(emb_1_struct, p=2, dim=1)
    emb_2_struct = F.normalize(emb_2_struct, p=2, dim=1)

    # è®¡ç®—ç»“æ„ç›¸ä¼¼åº¦
    sim_struct = torch.mm(emb_1_struct, emb_2_struct.T)

    # 3. èåˆ SBERT (å¦‚æœæä¾›)
    final_sim_matrix = sim_struct  # é»˜è®¤

    if sbert_1 is not None and sbert_2 is not None and alpha < 1.0:
        # å †å  SBERT å‘é‡
        emb_1_sem = torch.stack([sbert_1[i]
                                for i in kg1_ids]).to(config.DEVICE)
        emb_2_sem = torch.stack([sbert_2[i]
                                for i in kg2_ids]).to(config.DEVICE)

        # å½’ä¸€åŒ–
        emb_1_sem = F.normalize(emb_1_sem, p=2, dim=1)
        emb_2_sem = F.normalize(emb_2_sem, p=2, dim=1)

        # è®¡ç®—è¯­ä¹‰ç›¸ä¼¼åº¦
        sim_sem = torch.mm(emb_1_sem, emb_2_sem.T)

        # ã€æ ¸å¿ƒèåˆå…¬å¼ã€‘
        final_sim_matrix = (alpha * sim_struct) + ((1.0 - alpha) * sim_sem)

    # ç§»å› CPU æ–¹ä¾¿åç»­æ’åº
    final_sim_matrix = final_sim_matrix.cpu()

    # 4. è®¡ç®—æŒ‡æ ‡
    hits_at = {k: 0 for k in k_values}
    mrr = 0.0

    for id1, id2 in tqdm(valid_test_pairs, desc="Evaluating"):
        idx1 = id_to_idx_1[id1]
        target_idx2 = id_to_idx_2[id2]

        scores = final_sim_matrix[idx1]
        rank = (torch.argsort(scores, descending=True)
                == target_idx2).nonzero().item() + 1

        mrr += 1.0 / rank
        for k in k_values:
            if rank <= k:
                hits_at[k] += 1

    count = len(valid_test_pairs)
    mrr /= count
    hits_at = {k: (v/count)*100 for k, v in hits_at.items()}

    print(f"Hits@k: {hits_at}")
    print(f"MRR: {mrr:.4f}")
    return hits_at, mrr
