# ğŸ“„ config.py
import torch

# =========================================================
# ğŸ›ï¸ ã€æ ¸å¿ƒæ§åˆ¶å°ã€‘
# =========================================================
CURRENT_DATASET_NAME = 'dbp15k'  # æˆ– 'demo'

# ğŸ§  æ¨¡å‹æ¶æ„é€‰æ‹©
# 'gcn' -> å…¨èšåˆ GCN
# 'decoupled' -> è§£è€¦è”é‚¦ (Private GCN + Shared MLP)
MODEL_ARCH = 'decoupled'

# ğŸ”¬ å®éªŒæ¨¡å¼: True=è”é‚¦èšåˆ, False=å­¤ç«‹è®­ç»ƒ
USE_AGGREGATION = True

# =========================================================
# âš™ï¸ ç¡¬ä»¶ä¸é€šç”¨é…ç½®
# =========================================================


def get_best_device():
    if torch.backends.mps.is_available():
        return torch.device("mps")
    elif torch.cuda.is_available():
        return torch.device("cuda")
    else:
        return torch.device("cpu")


DEVICE = get_best_device()

BERT_MODEL_NAME = 'paraphrase-multilingual-mpnet-base-v2'
BERT_DIM = 768
BERT_BATCH_SIZE = 32

# =========================================================
# ğŸ“š æ•°æ®é›†é¢„è®¾
# =========================================================
DATASET_CONFIGS = {
    'demo': {
        # è¯·ä¿®æ”¹ä¸ºæ‚¨å®é™…çš„ demo è·¯å¾„
        'base_path': "/Users/yihanbin/Documents/ç§‘ç ”/çŸ¥è¯†å›¾è°±/ä»£ç /KGE/FedKG/data/demo/",
        'transe_dim': 64, 'transe_epochs': 500, 'transe_batch': 8,
        'gcn_dim': 64, 'gcn_hidden': 128, 'gcn_layers': 2,
        'fl_rounds': 50, 'fl_local_epochs': 10, 'fl_batch': 8, 'fl_lr': 1e-3, 'fl_margin': 0.5,
        'eval_k': [1, 5, 10]
    },
    'dbp15k': {
        # è¯·ä¿®æ”¹ä¸ºæ‚¨å®é™…çš„ dbp15k è·¯å¾„
        'base_path': "/Users/yihanbin/Documents/ç§‘ç ”/çŸ¥è¯†å›¾è°±/ä»£ç /KGE/FedKG/data/dbp15k/zh_en/",
        'transe_dim': 300, 'transe_epochs': 1000, 'transe_batch': 2048,
        'gcn_dim': 300, 'gcn_hidden': 300, 'gcn_layers': 2,
        'fl_rounds': 100, 'fl_local_epochs': 5, 'fl_batch': 512, 'fl_lr': 1e-4,
        'fl_margin': 0.4,
        'gcn_dropout': 0.2,
        'eval_k': [1, 10, 50]
    }
}

if CURRENT_DATASET_NAME not in DATASET_CONFIGS:
    raise ValueError(f"æ•°æ®é›† '{CURRENT_DATASET_NAME}' æœªå®šä¹‰ï¼")

_cfg = DATASET_CONFIGS[CURRENT_DATASET_NAME]
BASE_PATH = _cfg['base_path']

TRANSE_DIM = _cfg['transe_dim']
TRANSE_EPOCHS = _cfg['transe_epochs']
TRANSE_BATCH_SIZE = _cfg['transe_batch']
TRANSE_LR = 0.001
TRANSE_MARGIN = 1.0
TRANSE_P_NORM = 2

GCN_DIM = _cfg['gcn_dim']
GCN_HIDDEN = _cfg['gcn_hidden']
GCN_DROPOUT = _cfg.get('gcn_dropout', 0.3)
GCN_LAYERS = _cfg['gcn_layers']

FL_ROUNDS = _cfg['fl_rounds']
FL_LOCAL_EPOCHS = _cfg['fl_local_epochs']
FL_BATCH_SIZE = _cfg['fl_batch']
FL_LR = _cfg['fl_lr']
FL_MARGIN = _cfg['fl_margin']

# --- è”é‚¦åŸå‹å¯¹æ¯”å­¦ä¹  (Prototype Contrastive Learning) ---
USE_PROTOTYPES = True
PROTO_NUM = 100
PROTO_LAMBDA = 0.1
PROTO_TEMPERATURE = 0.1

EVAL_K_VALUES = _cfg['eval_k']

# --- ğŸ”¥ [æ–°å¢] èåˆæ¨ç†é…ç½® ---
# 0.42 æ˜¯å®éªŒå¾—å‡ºçš„æœ€ä½³å€¼ (42% GCN + 58% SBERT)
EVAL_FUSION_ALPHA = 0.42

if MODEL_ARCH == 'gcn':
    MODEL_INFO = f"GCN (Dim={GCN_DIM}, Hidden={GCN_HIDDEN}, Drop={GCN_DROPOUT})"
elif MODEL_ARCH == 'projection':
    MODEL_INFO = f"TransE (Dim={TRANSE_DIM}) + MLP Projection"
else:
    MODEL_INFO = "Decoupled (GCN+MLP)"

print(f"âš¡ï¸ é…ç½®åŠ è½½å®Œæ¯•: [{CURRENT_DATASET_NAME}]")
print(f"   ğŸ•¸ï¸ æ¶æ„: {MODEL_INFO}")
print(f"   ğŸ² æ¨¡å¼: {'è”é‚¦èšåˆ' if USE_AGGREGATION else 'å­¤ç«‹è®­ç»ƒ'}")
print(f"   âš–ï¸ èåˆ Alpha: {EVAL_FUSION_ALPHA}")
print("-" * 50)
