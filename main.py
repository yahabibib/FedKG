import hydra
from omegaconf import DictConfig, OmegaConf
import logging
import os
import torch

# --- å¯¼å…¥æˆ‘ä»¬é‡æ„åçš„æ ¸å¿ƒç»„ä»¶ ---
# 1. æ•°æ®å±‚
from src.data.dataset import AlignmentTaskData
# 2. å·¥å…·å±‚
from src.utils.device_manager import DeviceManager
from src.utils.metrics import eval_alignment
from src.utils.logger import log_experiment_result
# 3. è”é‚¦å±‚
from src.federation.server import Server
from src.federation.client_sbert import ClientSBERT
from src.federation.strategy import PseudoLabelGenerator

# è·å– Hydra çš„ loggerï¼Œå®ƒä¼šè‡ªåŠ¨å°†æ—¥å¿—è¾“å‡ºåˆ° outputs/æ—¥æœŸ/æ—¶é—´/main.log
log = logging.getLogger(__name__)


@hydra.main(config_path="configs", config_name="config", version_base="1.2")
def main(cfg: DictConfig):
    """
    FedAnchor 2.0 ä¸»å…¥å£
    """
    # 1. æ‰“å°å®éªŒå…ƒä¿¡æ¯
    log.info(f"ğŸš€ Starting Experiment: {cfg.experiment_name}")
    log.info(
        f"âš™ï¸  Task Type: {cfg.task.type} | Mode: {cfg.task.strategy.text_mode}")
    log.info(
        f"ğŸ’» Device Strategy: {cfg.system.device} (Offload: {cfg.system.memory.offload_to_cpu})")

    # æ‰“å°å®Œæ•´é…ç½®æ–¹ä¾¿è°ƒè¯• (å¯é€‰)
    # log.info(f"\n{OmegaConf.to_yaml(cfg)}")

    # 2. åˆå§‹åŒ–è®¾å¤‡ç®¡ç†å™¨ (å¤„ç† MPS/CUDA å’Œæ˜¾å­˜ç­–ç•¥)
    dm = DeviceManager(cfg.system)

    # 3. åŠ è½½æ•°æ® (AlignmentTaskData ä¼šè‡ªåŠ¨è§£æ source/target é…ç½®)
    log.info("ğŸ“š Loading Datasets...")
    try:
        # è¿™é‡Œä¼šè‡ªåŠ¨åŠ è½½ ent_ids, pairs, desc, polish ç­‰æ‰€æœ‰æ–‡ä»¶
        task_data = AlignmentTaskData(cfg.data)
    except FileNotFoundError as e:
        log.error(f"âŒ Data loading failed: {e}")
        return
    except Exception as e:
        log.exception(f"âŒ Unexpected error during data loading: {e}")
        return

    # 4. åˆå§‹åŒ–è”é‚¦ç»„ä»¶
    # Server: è´Ÿè´£èšåˆï¼Œå¸¸é©» CPU
    server = Server(cfg)

    # Client: è´Ÿè´£è®­ç»ƒï¼Œæ ¹æ® DeviceManager ç­–ç•¥ä½¿ç”¨ GPU/MPS
    # æ³¨æ„ï¼šæˆ‘ä»¬å°† task_data.source (KGDataset) ä¼ ç»™ C1ï¼Œtask_data.target ä¼ ç»™ C2
    c1 = ClientSBERT("C1", cfg, task_data.source, dm)
    c2 = ClientSBERT("C2", cfg, task_data.target, dm)

    # 5. ä»»åŠ¡åˆ†å‘ (Task Dispatch)
    # æ ¹æ® config.yaml ä¸­çš„ task.type å†³å®šè¿è¡Œå“ªä¸ªæµç¨‹
    if cfg.task.type == 'sbert':
        run_sbert_workflow(cfg, server, c1, c2, task_data.test_pairs, dm)
    elif cfg.task.type == 'structure':
        log.info("ğŸš§ Structure workflow (GCN) is under construction...")
        # run_structure_workflow(cfg, server, c1, c2, task_data)
    else:
        log.error(f"âŒ Unknown task type: {cfg.task.type}")


def run_sbert_workflow(cfg, server, c1, c2, test_pairs, dm):
    """
    SBERT æ··åˆå¾®è°ƒä¸»æµç¨‹ (SBERT Mixed Fine-tuning Workflow)
    """
    results = []
    rounds = cfg.task.federated.rounds
    threshold = cfg.task.strategy.pseudo_threshold
    text_mode = cfg.task.strategy.text_mode

    for r in range(rounds + 1):
        log.info(f"\n{'='*40}\nğŸ”„ Round {r}/{rounds} [{text_mode}]\n{'='*40}")

        # --- Step 1: ç¼–ç  (Encode) ---
        log.info("   Encoding Entities...")

        # 1.1 ç¼–ç  Description (ä½œä¸ºä¸»è¦çš„è¯­ä¹‰é”šç‚¹)
        ids1_desc, emb1_desc = c1.encode('desc')
        ids2_desc, emb2_desc = c2.encode('desc')

        # 1.2 ç¼–ç  Polished (ä½œä¸ºç»“æ„åŒ–æ–‡æœ¬çš„å¯¹ç…§ç»„ï¼Œæˆ–æ··åˆè®­ç»ƒçš„ç´ æ)
        ids1_poly, emb1_poly = c1.encode('polish')
        ids2_poly, emb2_poly = c2.encode('polish')

        # --- Step 2: è¯„ä¼° (Evaluate) ---
        # æˆ‘ä»¬è¿›è¡ŒåŒé‡è¯„ä¼°ï¼Œæ—¢çœ‹æ¨¡å‹å¯¹è‡ªç„¶è¯­è¨€(Desc)çš„ç†è§£ï¼Œä¹Ÿçœ‹å¯¹ç»“æ„åŒ–æ–‡æœ¬(Polish)çš„ç†è§£

        # 2.1 è¯„ä¼° Description
        log.info("   ğŸ“Š Eval [Description Input]...")
        # æ„å»º {id: tensor} å­—å…¸ä¾› eval_alignment ä½¿ç”¨
        d1_desc = {id: emb1_desc[i] for i, id in enumerate(ids1_desc)}
        d2_desc = {id: emb2_desc[i] for i, id in enumerate(ids2_desc)}

        h_d, m_d = eval_alignment(d1_desc, d2_desc, test_pairs, device='cpu')

        # 2.2 è¯„ä¼° Polished
        log.info("   ğŸ“Š Eval [Polished Input]...")
        d1_poly = {id: emb1_poly[i] for i, id in enumerate(ids1_poly)}
        d2_poly = {id: emb2_poly[i] for i, id in enumerate(ids2_poly)}

        h_p, m_p = eval_alignment(d1_poly, d2_poly, test_pairs, device='cpu')

        # æ‰“å°å¹¶æ”¶é›†ç»“æœ
        log.info(
            f"   ğŸ† Result R{r}: Desc H@1={h_d[1]:.2f}% | Polish H@1={h_p[1]:.2f}%")

        current_metrics = {
            "round": r,
            "desc_hits1": h_d[1], "desc_mrr": m_d,
            "poly_hits1": h_p[1], "poly_mrr": m_p
        }
        results.append(current_metrics)

        # å¦‚æœæ˜¯æœ€åä¸€è½®ï¼Œè¯„ä¼°å®Œå°±ç»“æŸï¼Œä¸è¿›è¡Œè®­ç»ƒ
        if r == rounds:
            break

        # --- Step 3: ç­–ç•¥ - ç”Ÿæˆä¼ªæ ‡ç­¾ (Strategy) ---
        log.info(f"   Generating Pseudo-labels (Threshold={threshold})...")

        # æ ¸å¿ƒé€»è¾‘ï¼šæˆ‘ä»¬å§‹ç»ˆä¿¡ä»» Description ç”Ÿæˆçš„ä¼ªæ ‡ç­¾ï¼Œå› ä¸ºå®ƒçš„è¯­ä¹‰è´¨é‡æœ€é«˜ (Zero-shot 58% vs 41%)
        # ä½¿ç”¨ src.federation.strategy.PseudoLabelGenerator
        pairs_idx = PseudoLabelGenerator.generate(
            emb1_desc, emb2_desc, threshold, device='cpu')

        log.info(f"   ğŸŒ± Found {len(pairs_idx)} high-confidence pairs.")

        # å®‰å…¨æ£€æŸ¥ï¼šå¦‚æœä¼ªæ ‡ç­¾å¤ªå°‘ï¼Œå¼ºè¡Œè®­ç»ƒä¼šå¯¼è‡´è¿‡æ‹Ÿåˆæˆ–å´©å¡Œ
        if len(pairs_idx) < 50:
            log.warning(
                "   âš ï¸ Too few pairs (<50), skipping training this round.")
            continue

        # --- Step 4: å‡†å¤‡è®­ç»ƒæ•°æ® (Data Preparation) ---
        # pairs_idx æ˜¯ emb1_desc å’Œ emb2_desc çš„ç´¢å¼•å¯¹ (index)
        p_idx1 = [p[0] for p in pairs_idx]
        p_idx2 = [p[1] for p in pairs_idx]

        # æå–äº¤å‰ç›®æ ‡ (Cross-target): C1 å­¦ä¹  C2 çš„ç‰¹å¾ï¼ŒC2 å­¦ä¹  C1 çš„ç‰¹å¾

        # ç›®æ ‡ A: Description Embedding (å¼ºè¯­ä¹‰)
        target_desc_for_c1 = emb2_desc[p_idx2]
        target_desc_for_c2 = emb1_desc[p_idx1]

        # ç›®æ ‡ B: Polished Embedding (å¼ºç»“æ„) - ç”¨äºæ··åˆè®­ç»ƒ
        target_poly_for_c1 = emb2_poly[p_idx2]
        target_poly_for_c2 = emb1_poly[p_idx1]

        # é€šçŸ¥ Client å‡†å¤‡ DataLoader
        # Client å†…éƒ¨ä¼šæ ¹æ® cfg.task.strategy.text_mode å†³å®šå¦‚ä½•æ··åˆè¿™äº›æ•°æ®
        c1.prepare_training_data(
            p_idx1, target_desc_for_c1, target_poly_for_c1)
        c2.prepare_training_data(
            p_idx2, target_desc_for_c2, target_poly_for_c2)

        # --- Step 5: æœ¬åœ°è®­ç»ƒ (Local Training) ---
        # ä¸²è¡Œè®­ç»ƒï¼šC1 ä¸Š GPU -> ç»ƒå®Œ -> ä¸‹ GPU -> C2 ä¸Š GPU
        # DeviceManager ä¼šåœ¨ Client å†…éƒ¨è‡ªåŠ¨ç®¡ç†æ˜¾å­˜

        w1, l1 = c1.train()
        log.info(f"   ğŸ“‰ C1 Loss: {l1:.6f}")

        w2, l2 = c2.train()
        log.info(f"   ğŸ“‰ C2 Loss: {l2:.6f}")

        # --- Step 6: èšåˆ (Aggregation) ---
        # Server æ‰§è¡Œ FedAvg
        server.aggregate([w1, w2])

        # åˆ†å‘å…¨å±€å‚æ•°
        global_weights = server.get_global_weights()
        c1.model.load_state_dict(global_weights)
        c2.model.load_state_dict(global_weights)

        # å¼ºåˆ¶æ˜¾å­˜æ¸…ç† (Double Check)
        dm.clean_memory()

    # --- æµç¨‹ç»“æŸ ---

    # 1. ä¿å­˜æœ€ä½³æ¨¡å‹
    if cfg.task.checkpoint.save_best:
        server.save_model(suffix=f"{text_mode}_round{rounds}")

    # 2. è®°å½•æœ€ç»ˆç»“æœåˆ° JSON
    log_experiment_result(
        cfg.experiment_name,
        cfg.data.name,
        results[-1],
        config=cfg
    )
    log.info("âœ… SBERT Workflow Completed Successfully.")


if __name__ == "__main__":
    main()
